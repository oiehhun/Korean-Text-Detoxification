{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import shap\n",
    "import scipy as sp\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoModel\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Sentence</th>\n",
       "      <th>Our Model</th>\n",
       "      <th>w/o fewshot</th>\n",
       "      <th>w/o MASK</th>\n",
       "      <th>Nothing ( just Instruction )</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n",
       "      <td>아.. 정말정말 술이 땡기네... 오늘 저녁은 꽃등심이다ㅠㅜ</td>\n",
       "      <td>아 정말 너무 슬퍼... 오늘 저녁은 꽃등심이네요.😢</td>\n",
       "      <td>정말 슬프네요... 오늘 저녁은 꽃등심이에요.</td>\n",
       "      <td>{'정말 슬프네요... 오늘 저녁은 꽃등심이에요.ㅠㅜ\\n'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>아무리 법이 불공정해도 어떤 권리로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>법이 완벽하지 않다고 해도, 어떤 권한으로 개인 정보를 여러 사람에게 공개하는지 이...</td>\n",
       "      <td>법이 완벽하지 않을 수 있지만, 어떤 권한으로 개인의 신상 정보를 많은 사람에게 공...</td>\n",
       "      <td>법이 만족스럽지 못할 수 있지만, 개인의 신상 정보를 공개하는 것은 적절한 절차를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>다음도 들어와라하고...다른 의견내는 유튜버 목 자르고....추아줌마 꺼 여기저기서...</td>\n",
       "      <td>다음도 들어와라 하고... 다른 의견 내는 유튜버를 배제하고... 추측이 여기저기서...</td>\n",
       "      <td>다음에도 참여를 요청하며, 다른 의견을 제시하는 유튜버에게 압력을 가하고... 여러...</td>\n",
       "      <td>다음도 참여하라고 하고... 다른 의견을 내는 유튜버에게 압력을 가하고... 추 장...</td>\n",
       "      <td>다음에도 참여를 요청하고, 다른 의견을 제시하는 유튜버에 대한 조치를 취하며, 여러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>개별 공무원 뷰웅들의 헷지랄에 뭔 청와대까지 들먹이는지... 빠끄네 때도 순시리가 ...</td>\n",
       "      <td>개별 공무원 분들의 활동에 왜 청와대까지 언급하는지 모르겠네요. 이전에도 문제가 있...</td>\n",
       "      <td>공무원들의 행동에 왜 청와대까지 거론되는지 모르겠네요. 이전 정부 때도 문제가 있었...</td>\n",
       "      <td>개별 공무원들의 행동에 왜 청와대까지 언급하는지 모르겠네요... 이전에도 문제는 개...</td>\n",
       "      <td>공무원 개인의 행동을 가지고 청와대까지 언급하는 것은 다소 과한 것 같습니다. 이전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>대깨문이 문재인 협박범을 쉴드치네? 역시 대가리가 붕어인듯~</td>\n",
       "      <td>지지자들이 문재인 협박범을 옹호하네? 역시 생각이 단순한 듯~</td>\n",
       "      <td>일부 사람들이 문재인 전 대통령을 지지하는 것 같네요. 역시 의견이 갈리는 모양이네요.</td>\n",
       "      <td>문재인 전 대통령을 지지하는 분들이 협박범을 옹호하고 있네요? 역시 생각이 다른 것...</td>\n",
       "      <td>{'문재인 전 대통령을 지지하는 분들이 협박범을 옹호하는 것 같네요. 의견이 다를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>펨코 이 씨발련들 싸가지 왤케 없냐저 정도 길이면 그냥 건너갈 수도 있지누군가의 엄...</td>\n",
       "      <td>펨코 이 사람들 예의가 왜 이렇게 없나요? 저 정도 길이면 그냥 건너갈 수도 있지....</td>\n",
       "      <td>펨코 여러분, 댓글을 좀 더 예의 있게 달아주셨으면 해요. 저 정도 길이면 건너갈 ...</td>\n",
       "      <td>펨코 이 사람들 예의가 왜 이렇게 없나요? 저 정도 길이면 그냥 건너갈 수도 있잖아...</td>\n",
       "      <td>펨코 이용자분들, 좀 더 예의를 갖추면 좋겠어요. 저 정도 길이면 건너갈 수도 있을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>홍어새끼들 존나 많네 이정도 디테일보고 주작주작 거리고 있네  씨발년들아 태어나기전...</td>\n",
       "      <td>사람들 정말 많네요. 이정도 디테일 보고도 의심하고 있네요. 여러분, 태어나기 전 ...</td>\n",
       "      <td>많은 사람들이 이 정도의 디테일을 보고 의심하고 있는 것 같네요. 태어나기 전 일을...</td>\n",
       "      <td>여기 사람들 정말 많네요. 이 정도 디테일을 보고도 의심이 많으시네요. 태어나기 전...</td>\n",
       "      <td>여기 사람들 정말 많네요. 이렇게 세세한 부분까지 살펴보고 의심하는 분위기가 있네요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>손주은 센세가 떠오르노 ㅋㅋㅋㅋㅋㅋㅋ강의시간에 너 공부 안하면 창녀보다 못한 삶을 ...</td>\n",
       "      <td>손주은 선생님이 생각나네요. 강의시간에 너 공부 안 하면 힘든 삶을 살게 될 거라는...</td>\n",
       "      <td>손주은 선생님이 생각나네요. 강의시간에 열심히 공부하지 않으면 힘든 삶을 살게 될 ...</td>\n",
       "      <td>손주은 선생님이 생각나네요. 강의시간에 공부를 열심히 하지 않으면 어려운 삶을 살게...</td>\n",
       "      <td>손주은 선생님의 강의가 생각나네요. 강의 중에 공부를 열심히 하지 않으면 어려운 삶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>이래서 애새끼 함부로 싸지르는거 아니다</td>\n",
       "      <td>이래서 아이를 함부로 낳는 건 아니다</td>\n",
       "      <td>아이를 함부로 낳는 것은 책임감 있는 행동이 아닙니다.</td>\n",
       "      <td>이래서 아이를 함부로 낳는 것이 아닙니다.</td>\n",
       "      <td>아이를 키우는 일은 신중하게 접근해야 하는 중요한 일입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>세금 내놓으라고 데모질 중 ㅋㅋ간첩, 도둑놈 새끼들이 대통령 해처먹으니까  나도 같...</td>\n",
       "      <td>세금을 요구하며 시위 중이네요. 부정한 방법으로 대통령 자리를 차지하니, 나도 혜택...</td>\n",
       "      <td>세금 문제로 시위가 벌어지고 있네요. 정치인들이 제대로 역할을 하지 못하면 국민들도...</td>\n",
       "      <td>세금을 제대로 관리하라는 요구로 시위가 벌어지고 있네요. 지도자들의 부정행위로 인해...</td>\n",
       "      <td>세금 문제로 시위가 많아지는 것 같네요. 지도자들의 행동이 국민에게 좋지 않은 영향...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1359 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Raw Sentence  \\\n",
       "0                       씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ   \n",
       "1     아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...   \n",
       "2     다음도 들어와라하고...다른 의견내는 유튜버 목 자르고....추아줌마 꺼 여기저기서...   \n",
       "3     개별 공무원 뷰웅들의 헷지랄에 뭔 청와대까지 들먹이는지... 빠끄네 때도 순시리가 ...   \n",
       "4                     대깨문이 문재인 협박범을 쉴드치네? 역시 대가리가 붕어인듯~   \n",
       "...                                                 ...   \n",
       "1354  펨코 이 씨발련들 싸가지 왤케 없냐저 정도 길이면 그냥 건너갈 수도 있지누군가의 엄...   \n",
       "1355  홍어새끼들 존나 많네 이정도 디테일보고 주작주작 거리고 있네  씨발년들아 태어나기전...   \n",
       "1356  손주은 센세가 떠오르노 ㅋㅋㅋㅋㅋㅋㅋ강의시간에 너 공부 안하면 창녀보다 못한 삶을 ...   \n",
       "1357                             이래서 애새끼 함부로 싸지르는거 아니다    \n",
       "1358  세금 내놓으라고 데모질 중 ㅋㅋ간첩, 도둑놈 새끼들이 대통령 해처먹으니까  나도 같...   \n",
       "\n",
       "                                              Our Model  \\\n",
       "0                     아.. 정말정말 술이 땡기네... 오늘 저녁은 꽃등심이다ㅠㅜ   \n",
       "1     아무리 법이 불공정해도 어떤 권리로 개인의 신상정보를 불특정 다수에게 공개하는지 도...   \n",
       "2     다음도 들어와라 하고... 다른 의견 내는 유튜버를 배제하고... 추측이 여기저기서...   \n",
       "3     개별 공무원 분들의 활동에 왜 청와대까지 언급하는지 모르겠네요. 이전에도 문제가 있...   \n",
       "4                    지지자들이 문재인 협박범을 옹호하네? 역시 생각이 단순한 듯~   \n",
       "...                                                 ...   \n",
       "1354  펨코 이 사람들 예의가 왜 이렇게 없나요? 저 정도 길이면 그냥 건너갈 수도 있지....   \n",
       "1355  사람들 정말 많네요. 이정도 디테일 보고도 의심하고 있네요. 여러분, 태어나기 전 ...   \n",
       "1356  손주은 선생님이 생각나네요. 강의시간에 너 공부 안 하면 힘든 삶을 살게 될 거라는...   \n",
       "1357                               이래서 아이를 함부로 낳는 건 아니다   \n",
       "1358  세금을 요구하며 시위 중이네요. 부정한 방법으로 대통령 자리를 차지하니, 나도 혜택...   \n",
       "\n",
       "                                            w/o fewshot  \\\n",
       "0                         아 정말 너무 슬퍼... 오늘 저녁은 꽃등심이네요.😢   \n",
       "1     법이 완벽하지 않다고 해도, 어떤 권한으로 개인 정보를 여러 사람에게 공개하는지 이...   \n",
       "2     다음에도 참여를 요청하며, 다른 의견을 제시하는 유튜버에게 압력을 가하고... 여러...   \n",
       "3     공무원들의 행동에 왜 청와대까지 거론되는지 모르겠네요. 이전 정부 때도 문제가 있었...   \n",
       "4      일부 사람들이 문재인 전 대통령을 지지하는 것 같네요. 역시 의견이 갈리는 모양이네요.   \n",
       "...                                                 ...   \n",
       "1354  펨코 여러분, 댓글을 좀 더 예의 있게 달아주셨으면 해요. 저 정도 길이면 건너갈 ...   \n",
       "1355  많은 사람들이 이 정도의 디테일을 보고 의심하고 있는 것 같네요. 태어나기 전 일을...   \n",
       "1356  손주은 선생님이 생각나네요. 강의시간에 열심히 공부하지 않으면 힘든 삶을 살게 될 ...   \n",
       "1357                     아이를 함부로 낳는 것은 책임감 있는 행동이 아닙니다.   \n",
       "1358  세금 문제로 시위가 벌어지고 있네요. 정치인들이 제대로 역할을 하지 못하면 국민들도...   \n",
       "\n",
       "                                               w/o MASK  \\\n",
       "0                             정말 슬프네요... 오늘 저녁은 꽃등심이에요.   \n",
       "1     법이 완벽하지 않을 수 있지만, 어떤 권한으로 개인의 신상 정보를 많은 사람에게 공...   \n",
       "2     다음도 참여하라고 하고... 다른 의견을 내는 유튜버에게 압력을 가하고... 추 장...   \n",
       "3     개별 공무원들의 행동에 왜 청와대까지 언급하는지 모르겠네요... 이전에도 문제는 개...   \n",
       "4     문재인 전 대통령을 지지하는 분들이 협박범을 옹호하고 있네요? 역시 생각이 다른 것...   \n",
       "...                                                 ...   \n",
       "1354  펨코 이 사람들 예의가 왜 이렇게 없나요? 저 정도 길이면 그냥 건너갈 수도 있잖아...   \n",
       "1355  여기 사람들 정말 많네요. 이 정도 디테일을 보고도 의심이 많으시네요. 태어나기 전...   \n",
       "1356  손주은 선생님이 생각나네요. 강의시간에 공부를 열심히 하지 않으면 어려운 삶을 살게...   \n",
       "1357                            이래서 아이를 함부로 낳는 것이 아닙니다.   \n",
       "1358  세금을 제대로 관리하라는 요구로 시위가 벌어지고 있네요. 지도자들의 부정행위로 인해...   \n",
       "\n",
       "                           Nothing ( just Instruction )  \n",
       "0                     {'정말 슬프네요... 오늘 저녁은 꽃등심이에요.ㅠㅜ\\n'}  \n",
       "1     법이 만족스럽지 못할 수 있지만, 개인의 신상 정보를 공개하는 것은 적절한 절차를 ...  \n",
       "2     다음에도 참여를 요청하고, 다른 의견을 제시하는 유튜버에 대한 조치를 취하며, 여러...  \n",
       "3     공무원 개인의 행동을 가지고 청와대까지 언급하는 것은 다소 과한 것 같습니다. 이전...  \n",
       "4     {'문재인 전 대통령을 지지하는 분들이 협박범을 옹호하는 것 같네요. 의견이 다를 ...  \n",
       "...                                                 ...  \n",
       "1354  펨코 이용자분들, 좀 더 예의를 갖추면 좋겠어요. 저 정도 길이면 건너갈 수도 있을...  \n",
       "1355  여기 사람들 정말 많네요. 이렇게 세세한 부분까지 살펴보고 의심하는 분위기가 있네요...  \n",
       "1356  손주은 선생님의 강의가 생각나네요. 강의 중에 공부를 열심히 하지 않으면 어려운 삶...  \n",
       "1357                  아이를 키우는 일은 신중하게 접근해야 하는 중요한 일입니다.  \n",
       "1358  세금 문제로 시위가 많아지는 것 같네요. 지도자들의 행동이 국민에게 좋지 않은 영향...  \n",
       "\n",
       "[1359 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_excel(\"/home/xogns5037/KcELECTRA/datasets/Final_Evaluation.xlsx\")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"beomi/KcELECTRA-base\"\n",
    "MODEL_NAME = \"beomi/KcELECTRA-base-v2022\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model.load_state_dict(torch.load('/home/xogns5037/KcELECTRA/KcELECTRA_5_pth/checkpoint-4500/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 평가 지표(finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Raw Sentence': 0.0,\n",
       " 'Our Model': 0.9323031640912436,\n",
       " 'w/o fewshot': 0.9926416482707874,\n",
       " 'w/o MASK': 0.9610007358351729,\n",
       " 'Nothing ( just Instruction )': 0.9867549668874173}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0: curse, 1: non_curse\n",
    "def sentence_predict(sent):\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 입력된 문장 토크나이징\n",
    "    tokenized_sent = tokenizer(\n",
    "        sent,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    # 모델이 위치한 GPU로 이동 \n",
    "    tokenized_sent.to(device)\n",
    "\n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=tokenized_sent[\"input_ids\"],\n",
    "            attention_mask=tokenized_sent[\"attention_mask\"],\n",
    "            token_type_ids=tokenized_sent[\"token_type_ids\"]\n",
    "            )\n",
    "\n",
    "    # 결과 return\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu()\n",
    "    result = logits.argmax(-1)\n",
    "    if result == 0: # 악성댓글\n",
    "        result = 0\n",
    "    elif result == 1: # 정상댓글\n",
    "        result = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "accuracy = {}\n",
    "\n",
    "for column in eval_df.columns:\n",
    "    \n",
    "    pred = 0\n",
    "    total = len(eval_df[column])\n",
    "\n",
    "    for sent in eval_df[column]:\n",
    "        result = sentence_predict(sent)\n",
    "        # print(f\"sentence: {sent}, result: {result}\")\n",
    "        if result == 0:\n",
    "            continue\n",
    "        else:\n",
    "            pred += 1\n",
    "    accuracy[column] = pred/total\n",
    "\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "th",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
